# 목차
- [06/19](#0619)
  - [어노테이션 및 라벨링](#어노테이션-및-라벨링)
- [06/20](#0620)
  - [데이터 수정 및 추가](#데이터-수정-및-추가)
  - [모델 학습](#모델-학습)
  - [학습 결과](#학습-결과)
- [06/23](#0623)
  - [차량 감지 후, 거리 측정 알고리즘](#차량-감지-후-거리-측정-알고리즘)
- [06/24](#0624)
  - [차량 감지 알고리즘 최적화](#차량-감지-알고리즘-최적화)
- [06/26](#0626)
  - [PyQt 서버 생성 및 소켓 통신](#PyQt-서버-생성-및-소켓-통신)
- [06/27](#0627)
  - [디스플레이 GUI 구현](#디스플레이-GUI-구현)

# 6/26
## PyQt 서버 생성 및 소켓 통신

# 06/19
## 어노테이션 및 라벨링
약 7,000장의 이미지 중 약 **700장**의 이미지를 선별 후 어노테이션 및 라벨링 작업 수행

<img src="https://github.com/suhwanjo/Intel-Edge-AI-Project/assets/96771644/9966c968-bd13-4470-9571-9f9af81c8c4c" width="500" height="300">

# 06/20
## 데이터 수정 및 추가
약 4,000장의 이미지 중 약 **400장**의 이미지를 선별 후 어노테이션 및 라벨링 작업 수행  
1차 데이터 삭제 및 추가 -> 라벨링의 폭을 넓게 수정

<img src="https://github.com/suhwanjo/Intel-Edge-AI-Project/assets/96771644/440bf3d3-2b31-4b24-8d5d-a4ef37371ccc" width="500" height="300">

## 모델 학습
OTX의 YOLOX-TINY 모델로 학습

<img src="https://github.com/suhwanjo/Intel-Edge-AI-Project/assets/96771644/e9751dc8-d62a-440a-9f66-74058d65ae34" width="500" height="300">

## 학습 결과

### 모델
*1차 데이터 - **YOLOX-TINY**, 2차 데이터 - **SSD***

### 하이퍼 파라미터
| 속성                      | YOLOX-TINY | SSD   |
|--------------------------|--------------|-----------|
| batch_size               | 8            | 8         |
| inference_batch_size     | 8            | 8         |
| learning_rate            | 0.0002       | 0.01      |
| learning_rate_warmup_iters| 3           | 3         |
| num_iters                | 200          | 200       |

#### 훈련 성능 (mode: train)
| 항목                | YOLOX-TINY | SSD   |
| ------------------- | -----------| ------| 
| Epoch               | 50         | 63    |
| Iteration           | 246        | 634   |
| Learning Rate       | 0.0        | 0.0   |
| Memory              | 4806       | 3948  |
| Current Iterations  | 12299      | 39941 |
| Data Time           | 0.00948    | 0.00666 |
| Loss (Class)        | 0.50077    | 0.89745 |
| Loss (BBox)         | 1.72361    | 0.41344 |
| Loss (Object)       | 0.53585    |      |
| 총 Loss             | 2.76023    | 1.31089 |
| Gradient Norm       | 20.67017   | 4.01689 |
| Time                | 0.3692     | 0.17115 |

#### F-Measure(정밀도와 재현율의 조화 평균)
| 항목                           | YOLOX-TINY   | SSD           |
| ----------------------------   | ------------ | ------------- |
| F-Measure | 0.9143       | 0.9085        |

#### 경과 시간
| 항목                           | YOLOX-TINY   | SSD           |
| ----------------------------   | ------------ | ------------- |
| 경과 시간                      | 1:19:55.974  | 1:57:44.716   |

# 06/23
## 차량 감지 후, 거리 측정 알고리즘
- *test_depth2.py*
    - *특정 영역 설정 → 해당 영영에 있는 차량만 감지 → 감지된 차량 중에 y축이 가장 큰 객체만 depth 측정(**전체 프레임**에 대해서 depth 측정) → 값이 200 초과인 경우에 문구(임시) 출력*
    - *기존 코드 대비 **약 20% 시간 단축***

- *test_depth3.py*
    - *특정 영역 설정 → 해당 영역에 있는 차량만 감지 → 감지된 차량 중에 y축이 가장 큰 객체만 depth 측정(**객체 상자 프레임**에 대해서만 depth 측정) → 값이 200 초과인 경우에 문구(임시) 출력*
    - *기존 코드 대비 **약 25% ~ 30% 시간 단축***

# 06/24
## 차량 감지 알고리즘 최적화

- *test_depth_opt_1.py*
    - 불필요한 출력 및 코드 최소화
    - 주석 추가
    - (test_depth2.py) 200라인 → (test_depth_opt_1.py)154라인

# 06/26
## PyQt 서버 생성 및 소켓 통신
- *라즈베리파이4 4GB 환경에서 On-device 형태로 진행하려 했지만,<br>
  모델 처리과정을 해당 환경에서는 버겁다고 판단하여 소켓 통신 방법으로 변경*
- *ras_server.py*
    - 기본 베이스만 작성 후 -> 통신 테스트 확인 완료
- *client.py*
    - 라즈베리파이에서 지속적으로 확인하기 불편하기 때문에<br>-> 로컬 환경에서 테스트하기 위한 코드

# 06/27
## 디스플레이 GUI 구현
- *초기 구현*
    - *qttest_please.py*
    - GUI 초기 구현 파일
- *최종 구현*
    - *qt.py*
    - GUI 최종 구현 파일